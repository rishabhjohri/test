{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de3e128",
   "metadata": {},
   "source": [
    "# Checkpoint 1 — Task 1.1 (Python): Insurance Claims Analysis\n",
    "**Group:** _A1_  \n",
    "**Members:** Rishabh Johri, Fayad Haseeb, Harsh Soni, Prashant Tandon \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3760fb25",
   "metadata": {},
   "source": [
    "## Objective\n",
    "- Load three Excel sheets (Policy, Car, Claim) and create a unified dataset.\n",
    "- Clean: trim/cast; extract numerics from torque/power; handle duplicates & missing values.\n",
    "- Explore: class balance, policy feature relationships, categorical summaries.\n",
    "- Answer required & added questions (Q1–Q6) with Python.\n",
    "- Quick model-based feature importance for claim drivers.\n",
    "- Visuals: correlation heatmap & claim pie chart.\n",
    "- Export cleaned CSV snapshot for SQL/BI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0843daf8",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, warnings, math, numpy as np, pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121dc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "POLICY_XLSX = \"/mnt/data/Policy features.xlsx\"\n",
    "CAR_XLSX    = \"/mnt/data/Car features.xlsx\"\n",
    "CLAIM_XLSX  = \"/mnt/data/Insurance claim.xlsx\"\n",
    "\n",
    "for p in [POLICY_XLSX, CAR_XLSX, CLAIM_XLSX]:\n",
    "    assert os.path.exists(p), f\"Missing file: {p}\"\n",
    "print(\"All input files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af62b7",
   "metadata": {},
   "source": [
    "## 1) Load & Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b189c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = pd.read_excel(POLICY_XLSX)\n",
    "car    = pd.read_excel(CAR_XLSX)\n",
    "claim  = pd.read_excel(CLAIM_XLSX)\n",
    "\n",
    "df = policy.merge(car, on=\"policy_id\").merge(claim, on=\"policy_id\")\n",
    "print(\"Shapes:\", policy.shape, car.shape, claim.shape, \"→ merged:\", df.shape)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b0638",
   "metadata": {},
   "source": [
    "## 2) Cleaning & Casting\n",
    "- Standardize column names (lower_snake).\n",
    "- Trim strings; remove exact duplicates.\n",
    "- Extract numerics from `max_torque` / `max_power`.\n",
    "- Cast boolean flags & target to {0,1}.\n",
    "- Quick missingness report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "\n",
    "for c in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "\n",
    "dup = df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Removed duplicates: {dup} (now {df.shape})\")\n",
    "\n",
    "\n",
    "def extract_num(s):\n",
    "    return pd.to_numeric(pd.Series(s, dtype=\"object\").astype(str).str.extract(r'([-+]?\\d*\\.?\\d+)')[0], errors=\"coerce\")\n",
    "\n",
    "if \"max_torque\" in df.columns:\n",
    "    df[\"max_torque_num\"] = extract_num(df[\"max_torque\"])\n",
    "if \"max_power\" in df.columns:\n",
    "    df[\"max_power_num\"] = extract_num(df[\"max_power\"])\n",
    "\n",
    "\n",
    "for c in [col for col in df.columns if col.startswith(\"is_\")] + [\"is_claim\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = (df[c].map({\"Yes\":1,\"No\":0,\"True\":1,\"False\":0,1:1,0:0}).fillna(df[c]).astype(float))\n",
    "\n",
    "\n",
    "miss = df.isna().mean().sort_values(ascending=False)\n",
    "print(\"Top-20 missingness:\")\n",
    "display(miss.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886400f4",
   "metadata": {},
   "source": [
    "## 3) Dataset Snapshot\n",
    "Rows/Cols, duplicates, and class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c82fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "print(\"Duplicates:\", df.duplicated().sum())\n",
    "label_counts = df[\"is_claim\"].value_counts(dropna=False)\n",
    "label_pct = (label_counts/label_counts.sum()*100).round(2)\n",
    "display(pd.DataFrame({\"count\": label_counts, \"pct\": label_pct}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77dd7dd",
   "metadata": {},
   "source": [
    "## 4) Analyses — Required Questions\n",
    "\n",
    "### Q1. Analyse policy features. Any relation with `is_claim`?\n",
    "Compute Pearson correlations for policy-related numerics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc63c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "policy_cols = [c for c in [\"policy_tenure\",\"age_of_car\",\"age_of_policyholder\",\"population_density\",\"is_claim\"] if c in df.columns]\n",
    "corr_policy = df[policy_cols].corr(numeric_only=True)[\"is_claim\"].sort_values(ascending=False)\n",
    "display(corr_policy.to_frame(\"pearson_corr\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee11fd6",
   "metadata": {},
   "source": [
    "### Q2. Is the dataset balanced? Are there duplicates?\n",
    "Already summarized in the snapshot table above.\n",
    "\n",
    "### Q3. Investigate car features and find important features affecting `is_claim`.\n",
    "Use a quick model-based importance (Random Forest) on preprocessed data (OHE + imputation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y = df[\"is_claim\"].fillna(0).astype(int)\n",
    "X = df.drop(columns=[\"is_claim\",\"policy_id\"], errors=\"ignore\")\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False, min_frequency=0.01), cat_cols),\n",
    "    (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols)\n",
    "])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", n_jobs=-1, random_state=42)\n",
    "\n",
    "pipe = Pipeline([(\"prep\", pre), (\"rf\", rf)])\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "pipe.fit(X_tr, y_tr)\n",
    "proba = pipe.predict_proba(X_te)[:,1]\n",
    "auc = roc_auc_score(y_te, proba)\n",
    "print(\"Holdout ROC-AUC:\", round(auc, 4))\n",
    "\n",
    "\n",
    "ohe = pipe.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
    "cat_feats = list(ohe.get_feature_names_out(cat_cols)) if cat_cols else []\n",
    "all_feats = cat_feats + num_cols\n",
    "imp = pd.DataFrame({\"feature\": all_feats[:len(pipe.named_steps['rf'].feature_importances_)],\n",
    "                    \"importance\": pipe.named_steps[\"rf\"].feature_importances_}).sort_values(\"importance\", ascending=False)\n",
    "display(imp.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6087c",
   "metadata": {},
   "source": [
    "## 5) Analyses — Additional Questions\n",
    "\n",
    "### Q4. Which **car segment** has the highest claim percentage?\n",
    "### Q5. Do **safety features** (airbags, ESC, NCAP) reduce claims?\n",
    "### Q6. Do **fuel type** and **transmission** influence claims?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"segment\" in df.columns:\n",
    "    seg_rate = df.groupby(\"segment\")[\"is_claim\"].mean().sort_values(ascending=False)\n",
    "    display(seg_rate.to_frame(\"claim_rate\"))\n",
    "else:\n",
    "    print(\"segment column not found.\")\n",
    "\n",
    "\n",
    "to_check = []\n",
    "if \"ncap_rating\" in df.columns: to_check.append(\"ncap_rating\")\n",
    "if \"airbags\" in df.columns: to_check.append(\"airbags\")\n",
    "if \"is_esc\" in df.columns: to_check.append(\"is_esc\")\n",
    "\n",
    "for col in to_check:\n",
    "    grp = df.groupby(col)[\"is_claim\"].mean().sort_values(ascending=False)\n",
    "    print(f\"\\nClaim rate by {col}:\")\n",
    "    display(grp.to_frame(\"claim_rate\"))\n",
    "\n",
    "\n",
    "for col in [\"fuel_type\",\"transmission_type\"]:\n",
    "    if col in df.columns:\n",
    "        grp = df.groupby(col)[\"is_claim\"].mean().sort_values(ascending=False)\n",
    "        print(f\"\\nClaim rate by {col}:\")\n",
    "        display(grp.to_frame(\"claim_rate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fade7b",
   "metadata": {},
   "source": [
    "## 6) Visuals (Matplotlib only)\n",
    "- **Correlation Heatmap** (numeric features + `is_claim`).\n",
    "- **Pie Chart** for `is_claim` distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (matplotlib only)\n",
    "num_cols_all = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if \"is_claim\" in num_cols_all:\n",
    "    cols_for_corr = [c for c in num_cols_all if c != \"policy_id\"]\n",
    "    C = df[cols_for_corr].corr(numeric_only=True).values\n",
    "    labels = cols_for_corr\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    im = plt.imshow(C, aspect='auto')\n",
    "    plt.title(\"Correlation Heatmap (Numeric Features)\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.xticks(ticks=range(len(labels)), labels=labels, rotation=90)\n",
    "    plt.yticks(ticks=range(len(labels)), labels=labels)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Pie chart for class balance\n",
    "counts = df[\"is_claim\"].value_counts().sort_index()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(counts, labels=[str(i) for i in counts.index], autopct=\"%1.1f%%\", startangle=90)\n",
    "plt.title(\"Insurance Claim Distribution (is_claim)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c2d9a",
   "metadata": {},
   "source": [
    "## 7) Export Cleaned Snapshot\n",
    "Produces a CSV to reuse in SQL (Checkpoint 1.2) and Power BI (Checkpoint 2.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_csv = \"/mnt/data/cleaned_insurance.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976cf0e8",
   "metadata": {},
   "source": [
    "## 8) Conclusions \n",
    "- Dataset is **highly imbalanced** (≈ 94% no-claim vs 6% claim).\n",
    "- Policy features (e.g., `policy_tenure`) show stronger association with `is_claim` than many raw car specs.\n",
    "- Safety features (higher `ncap_rating`, `is_esc`=1, more `airbags`) trend toward **lower** claim rates.\n",
    "- Some segments and fuel/transmission types exhibit higher claim propensity; capture these in targeted strategies.\n",
    "- Use class-weighting/stratification for downstream ML; prefer ROC-AUC/PR-AUC for evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
